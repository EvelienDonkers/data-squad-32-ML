{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yaxTV5iyhQ82"
   },
   "source": [
    "# ML Tech Interview\n",
    "\n",
    "Hello and welcome to the Machine Learning Tech Interview. This interview will be divided in two parts: the theoretical part and the practical/coding part. \n",
    "\n",
    "### **I will review only the scripts that will be sent (by pull request on this repo) by 1:00 pm**\n",
    "\n",
    "Good Luck!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQjWqn__hQ85"
   },
   "source": [
    "## Theoretical Part\n",
    "\n",
    "Please answer the following questions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0X1MRGNhQ86"
   },
   "source": [
    "#### What are the assumptions of a linear model (or any other type of model)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9rLLjNphQ86"
   },
   "outputs": [],
   "source": [
    "We assume that events and factors are independent variables and there is an equal distribution of them. This could give a \n",
    "difficulty in predicting while it costs too much processing power if events are connected or new events occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XWNx7P4HhQ8_"
   },
   "source": [
    "#### What’s the difference between K Nearest Neighbor and K-means Clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hQ16LsGthQ8_"
   },
   "outputs": [],
   "source": [
    "K-means clustering does not describe boundaries the best, K nearest Neighbour will under preform if there are too \n",
    "many points in the dataset while it has to calculate too much and different points\n",
    "will have different positions on the graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iDDPRfBRhQ9B"
   },
   "source": [
    "#### How do you address overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h1TyBsLwhQ9D"
   },
   "outputs": [],
   "source": [
    "Overfitting means that a model fits to well and pays to much attention to details, a new point will become a complete new\n",
    "categories and in the end we  have to many categories and we cannot get any conclusions from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0dInW-RQhQ9G"
   },
   "source": [
    "#### Explain Naive Bayes algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U76IQ8xdhQ9H"
   },
   "outputs": [],
   "source": [
    "Naïve Bayes algorithms assume that particular events are unrelated to presence of other features, they predict things \n",
    "fairly fast and assume a normal distribution.  It can be used for real time prediction, text classification and \n",
    "recommended systems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-UsLyyonHYwN"
   },
   "source": [
    "#### When do you use an AUC-ROC score? What kind of information can you gather from it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jp5SotUdHrZf"
   },
   "outputs": [],
   "source": [
    "The AUC-ROC is used to measure the accuracy of a classification algorithm. The AUC-ROC area is a plot the True Positive \n",
    "Rate against the False Positive Rate. You can thus see how often your model is right about things that actually happen. \n",
    "If it’s better than 0.5 the model does better then chance, the closer too one the better your model can distinguish. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gMzc684hQ9J"
   },
   "source": [
    "#### What is cross validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yhBiZyJhQ9K"
   },
   "outputs": [],
   "source": [
    "You test every part of the dataset as test and as training set, afterwards you compare all the outcomes (accuracies) to see\n",
    "where there are differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqEQlGL2hQ9L"
   },
   "source": [
    "#### What are confounding variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r-8POEd6hQ9M"
   },
   "outputs": [],
   "source": [
    "In machine learning the algorithm assumes that every variable is an independent factor, but if there is a confounding \n",
    "variable it will give noise and give you the wrong information about correlation and it could introduce bias. It could \n",
    "get your model to over- or underfit and give wrong predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ixSZaNdhQ9P"
   },
   "source": [
    "#### If an important metric for our company stopped appearing in our data source, how would you investigate the causes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KOPUF1i3hQ9Q"
   },
   "outputs": [],
   "source": [
    "It would dependent on the company but in general terms I would use the following approach: first I would check if the \n",
    "information gathering is still working in the right way. Then I would check if every thing in the business is still \n",
    "working (is the website down? No wonder that we don’t get any website visits). Is it desirable that the important metric \n",
    "stops occurring? If it’s about a sentiment analysis of bad reviews and we are doing well it’s good, so I would look at \n",
    "the workflow. After this I would compare the workflows/data/scores of before in comparison to the workflow/data/scores we \n",
    "are using now by doing some visualisations. I would look at the elbow graph to see if I need another number of clusters. \n",
    "Afterwards I would check if it is over- or underfitting. If that all doesn’t help I guess it’s time to ask around and have\n",
    "coffees with the colleagues. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ko6vUaXshQ9S"
   },
   "source": [
    "## Practical Machine Learning\n",
    "\n",
    "In this challenge, you will showcase your knowledge in feature engineering, dimensionality reduction, model selection and evaluation, hyperparameter tuning, and any other techniques of machine learning.\n",
    "\n",
    "There isn't a correct solution to this challenge. All we would like to learn is your thinking process that demonstrates your knowledge, experience, and creativity in developing machine learning models. Therefore, in addition to developing the model and optimizing its performance, you should also elaborate your thinking process and justify your decisions thoughout the iterative problem-solving process.\n",
    "\n",
    "The suggested time to spend on this challenge is 90-120 minutes. If you don't have time to finish all the tasks you plan to do, simply document the to-dos at the end of your response.\n",
    "\n",
    "#### Instructions:\n",
    "\n",
    "- Download the housing prices data set (housing_prices.csv). The data is big enough to showcase your thoughts but not so that processing power will be a problem.\n",
    "- Using Python, analyze the features and determine which feature set to select for modeling.\n",
    "- Train and cross validate several regression models, attempting to accurately predict the SalePrice target variable.\n",
    "- Evaluate all models and show comparison of performance metrics.\n",
    "- State your thoughts on model performance, which model(s) you would select, and why.\n",
    "\n",
    "#### Deliverables Checklist:\n",
    "\n",
    "- Python code.\n",
    "- Your thinking process.\n",
    "- The features selected for machine learning.\n",
    "- The results (e.g., performance metrics) of your selected model(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3moKc9n4hQ9T"
   },
   "outputs": [],
   "source": [
    "See [Code ML interview] Evelien Donkers document :)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLtechInterview.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
